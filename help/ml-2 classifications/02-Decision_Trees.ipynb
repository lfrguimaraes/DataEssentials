{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML models: Decision Trees\n",
    "\n",
    "There is a very powerful type of algorithms in Machine Learning that it is good to know about: Decision Trees. These have been popularized since the appearance of the Random Forest, which turns out to be extremely powerful. In this course, we will see how to approach this algorithm in an intuitive way.\n",
    "\n",
    "## What you will learn in this course üßêüßê\n",
    "\n",
    "- What's a decision tree\n",
    "- What's a random forest\n",
    "- Set the depth of a random tree\n",
    "- Define a random number of trees in a forest\n",
    "\n",
    "## Decision Tree üå≤\n",
    "\n",
    "### Intuitive Explanation\n",
    "\n",
    "A decision tree is nothing more and nothing less than a series of conditions that, once verified, allow us to arrive at a decision. For our algorithm, this decision will be the prediction. We talk about a tree because the graphical representation is very similar to it. Let's see an example:\n",
    "\n",
    "![](https://essentials-assets.s3.eu-west-3.amazonaws.com/M01-Data_visualisation/D01-Data_visualisation/01-Data_Visualisation_with_Tableau/Decision_Trees_1.jpeg)\n",
    "\n",
    "Credit: [https://towardsdatascience.com/https-medium-com-lorrli-classification-and-regression-analysis-with-decision-trees-c43cdbc58054](https://towardsdatascience.com/https-medium-com-lorrli-classification-and-regression-analysis-with-decision-trees-c43cdbc58054)\n",
    "\n",
    "As we can see in this picture, we are trying to predict what we are going to do with our day. Among the possibilities we have:\n",
    "\n",
    "- _Stay In_\n",
    "- _Go to the beach_\n",
    "- _Go Running_\n",
    "- _Go to the movies_\n",
    "\n",
    "To predict our different possibilities, we have several variables:\n",
    "\n",
    "- _Work to do_ (Do I have work to do?)\n",
    "- _Outlook_ (What's the weather like?)\n",
    "- _Friends busy_ (Are my friends busy?)\n",
    "\n",
    "Depending on the different responses to these variables, we will be able to make a decision.\n",
    "\n",
    "Now that we have understood the intuitive functioning of the tree, we will be able to define the terms present in the graph.\n",
    "\n",
    "### Nodes \n",
    "\n",
    "The nodes in a decision tree correspond to the different explanatory variables. For example, _Work to Do_ is a node in the same way as _Outlook_?\n",
    "\n",
    "### Branches \n",
    "\n",
    "Within each of the explanatory variables, there are different possible categories. For example in _Outlook ?_ we have the categories :\n",
    "\n",
    "- Sunny\n",
    "- Over-cast\n",
    "- Rainy\n",
    "\n",
    "These different categories are what we call branches.\n",
    "\n",
    "### Leaf Node üçÅ\n",
    "\n",
    "Finally the leave nodes are the different results of your decision tree. As soon as we reach the end of a chain of conditions, we come across a leaf node. In the case of the graph above, we have 5 leave nodes.\n",
    "\n",
    "### Advantages and Disadvantages of Trees\n",
    "\n",
    "#### Advantages üëç\n",
    "\n",
    "- Easily explainable and understandable decision trees, making it a very popular Machine Learning algorithm.\n",
    "- You don't need a lot of preprocessing to make a decision tree work.\n",
    "- The decision tree is able to manage numerical but also categorical variables. Conversely, logistic regression manages categorical variables less well.\n",
    "\n",
    "#### Drawbacks üëé\n",
    "\n",
    "- The main drawback is that decision trees often overfit.\n",
    "- If some classes in your target variable are more present than others, your trees will often be biased.\n",
    "\n",
    "## Random Forest üå≤üå≤üå≤\n",
    "\n",
    "### Intuitive Explanation\n",
    "\n",
    "To counteract the problem of overfitting, Data Scientists use the concept of random forests. Instead of using a single decision tree, we will randomly create X number of random trees and look at the predictions of each of them.\n",
    "\n",
    "We will then take a majority vote of the decisions from each of the trees to make our prediction.\n",
    "\n",
    "### Advantages üëç\n",
    "\n",
    "- Random forest is one of the most powerful Machine Learning algorithms in terms of prediction. The more trees you increase the better the results.\n",
    "- Despite the fact that using a random number of trees makes the model more complex to explain, it remains very _white box_ and understandable for a beginner.\n",
    "\n",
    "### Drawbacks üëé\n",
    "\n",
    "- The main disadvantage of random forests is that they can be quite heavy in computing power if you ask to use a very large number of trees and want to test a large number of parameters.\n",
    "\n",
    "## Resources üìöüìö\n",
    "\n",
    "- Decision Trees - [https://bit.ly/2FFUjAn](https://scikit-learn.org/stable/modules/tree.html)\n",
    "- Classification & Regression Analysis with Decision Trees - [http://bit.ly/2bdDELb](https://towardsdatascience.com/https-medium-com-lorrli-classification-and-regression-analysis-with-decision-trees-c43cdbc58054)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
