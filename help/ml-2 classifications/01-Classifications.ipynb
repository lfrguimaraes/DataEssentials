{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models: Classification\n",
    "\n",
    "In the previous course, we saw linear regressions that allow you to predict a number (such as someone's salary). Classifications are another type of model that will help you predict a category.\n",
    "\n",
    "## What you will learn in this course üßêüßê\n",
    "\n",
    "- What are classification models\n",
    "- Building a logistic regression model\n",
    "- What are false positives and false negatives\n",
    "- Evaluating the performance of your model using confusion matrices\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "### Definition üìñ\n",
    "\n",
    "Unlike linear regressions, which predict a number, classification models predict a category. For example, if you are trying to predict whether someone will buy a product from you based on certain independent variables, you are in a classification problem because the categories you are trying to predict are \"yes, the person will buy the product\" or \"no, the person won't buy my product\".\n",
    "\n",
    "Logistic regressions are one category in classification models but you have many others like _decision trees_, _SVM (support vector machine)_ or Naive Bayes.\n",
    "\n",
    "### Equation üë©‚Äçüî¨\n",
    "\n",
    "#### Logistic Regression\n",
    "\n",
    "![](https://essentials-assets.s3.eu-west-3.amazonaws.com/M04-Machine-learning/Logistic_regression.png)\n",
    "\n",
    "When we did the linear regressions, we saw that our predictor was the line drawn by our model. In a logistic regression, the line is simply a boundary that separates two categories. In the graph above, we are trying to see whether a person will buy a product (represented by the number 1) or not buy a product (represented by the number 0). The line represents the probability that a person will buy (_purchased_) or not buy a product based on their Age.\n",
    "\n",
    "Mathematically, the logistic regression is based on the Logistic function:\n",
    "\n",
    "$$ y = \\frac{1}{1+e^{-k(x-x_0)}} $$\n",
    "\n",
    "Where: \n",
    "\n",
    "* $y$ is your target variable expressed in probability (i.e a number from 0 to 1)\n",
    "* $k$ is the steepness of the curve (i.e how fast the curve goes from the bottom to upper values)\n",
    "* $x$ is your feature variable \n",
    "* $x_0$ is the curve midpoint (usually 50%)\n",
    "\n",
    "In this example, we have only one independent variable and one constant. The equate is slightly more complex but it is simply to represent categories as probabilities, that's it. Instead of having only `0` and `1`, you will have values from `0` to `1` with any value in this interval. Depending on the probability obtained, the algorithm will know in which category to place our individual.\n",
    "\n",
    "## Log Loss üìâ\n",
    "\n",
    "### Definition \n",
    "\n",
    "As you know, in Machine Learning, we always try to minimize what we call a cost function. In the case of logistic regression , we use the *Log Loss* function that looks like this:\n",
    "\n",
    "$$ Log Loss = \\sum_{i=0}^n -y_ilog(\\hat{y_i}) - (1-y_i)log(1-\\hat{y_i}) $$\n",
    "\n",
    "Where: \n",
    "\n",
    "* $y_i$ is your actual target value \n",
    "* $\\hat{y_i}$ is your model's prediction \n",
    "\n",
    "This formula is a little more complicated and you don't really need to understand it at all. The whole idea behind it is to make sure the algorithm predictions get closer to the actual target value. \n",
    "\n",
    "\n",
    "#### How to make our classification\n",
    "\n",
    "Now that we have drawn the line, we can begin our interpretations. Since our model this time is probabilistic, data points with a probability greater than 50% will belong to category A, while points with a probability less than 50% will belong to category B.\n",
    "\n",
    "Let's take an example. Based on some independent variables, we have found that person A has a 60% chance of buying the product. He will therefore be considered a \"buyer\" for our model. On the other hand, if this time we have a person B who has only a 45% chance of buying the product, he will be considered a \"non-buyer\".\n",
    "\n",
    "### False Positives & False Negatives üòà\n",
    "\n",
    "Since our model is based on probability, it can be wrong sometimes. False positives and false negatives represent the errors in our model.\n",
    "\n",
    "#### False Positive\n",
    "\n",
    "Let's continue with the example from above. If our model categorizes person A as a \"buyer\" and that person in reality does not buy the product then we are dealing with a false positive. The model expected a positive result, which in the end did not happen.\n",
    "\n",
    "#### False Negative\n",
    "\n",
    "Conversely, if person B, whom the model predicted as a non-buyer, finally buys the product, this is a false negative. We predicted a negative result but it didn't happen...\n",
    "\n",
    "#### Pay attention to false positives and ESPECIALLY to false negatives.\n",
    "\n",
    "Be aware of false positives and negatives because a prediction error can have more or less serious consequences depending on what you are trying to predict. For example, if you are a scientist trying to predict an earthquake and you come across a false negative (i.e. you predicted that the earthquake would not happen when it did), no one was actually prepared for the event.\n",
    "\n",
    "Generally speaking, false negatives are worse than false positives because in the first case no one is prepared for the event to happen. In the second case, you are prepared for it, and even if it doesn't happen, it's not the worst.\n",
    "\n",
    "### How to evaluate your model\n",
    "\n",
    "#### Confusion matrix\n",
    "\n",
    "![](https://essentials-assets.s3.eu-west-3.amazonaws.com/M04-Machine-learning/confusion_matrix.png)\n",
    "\n",
    "One of the quick and easy ways to measure the performance of your model using confusion matrices. The idea is to see the predictions that your model was right as well as the false positives and false negatives. By summing the errors on the prediction total you have the accuracy rate of your model.\n",
    "\n",
    "## Resources üìöüìö\n",
    "\n",
    "- Implementing Logistic Regression - [https://bit.ly/2FFUjAn](https://bit.ly/2FFUjAn)\n",
    "- Logistic Regression - [http://bit.ly/2bdDELb](http://bit.ly/2bdDELb)\n",
    "- Summary of Probability - [http://bit.ly/2m8YgDR](http://bit.ly/2m8YgDR)\n",
    "- Confusion Matrix - [http://bit.ly/2xApsRz](http://bit.ly/2xApsRz)\n",
    "- False Positives & False Negatives - [http://bit.ly/2FmhMql](http://bit.ly/2FmhMql)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
